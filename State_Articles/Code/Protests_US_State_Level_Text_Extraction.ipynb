{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "from newspaper import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV files\n",
    "alabama_file = \"protests_project/protests_blm_alabama_20200525_20200606_v3.csv\"\n",
    "alaska_file = \"protests_project/protests_blm_alaska_20200525_20200606_v3.csv\"\n",
    "arizona_file = \"protests_project/protests_blm_arizona_20200525_20200606_v3.csv\"\n",
    "arkansas_file = \"protests_project/protests_blm_arkansas_20200525_20200606_v3.csv\"\n",
    "california_file = \"protests_project/protests_blm_california_20200525_20200606_v3.csv\"\n",
    "colorado_file = \"protests_project/protests_blm_colorado_20200525_20200606_v3.csv\"\n",
    "connecticut_file = \"protests_project/protests_blm_connecticut_20200525_20200606_v3.csv\"\n",
    "delaware_file = \"protests_project/protests_blm_delaware_20200525_20200606_v3.csv\"\n",
    "georgia_file = \"protests_project/protests_blm_georgia_20200525_20200606_v3.csv\"\n",
    "hawaii_file = \"protests_project/protests_blm_hawaii_20200525_20200606_v3.csv\"\n",
    "idaho_file = \"protests_project/protests_blm_idaho_20200525_20200606_v3.csv\"\n",
    "illinois_file = \"protests_project/protests_blm_illinois_20200525_20200606_v3.csv\"\n",
    "indiana_file = \"protests_project/protests_blm_indiana_20200525_20200606_v3.csv\"\n",
    "iowa_file = \"protests_project/protests_blm_iowa_20200525_20200606_v3.csv\"\n",
    "kansas_file = \"protests_project/protests_blm_kansas_20200525_20200606_v3.csv\"\n",
    "kentucky_file = \"protests_project/protests_blm_kentucky_20200525_20200606_v3.csv\"\n",
    "louisiana_file = \"protests_project/protests_blm_louisiana_20200525_20200606_v3.csv\"\n",
    "maine_file = \"protests_project/protests_blm_maine_20200525_20200606_v3.csv\"\n",
    "maryland_file = \"protests_project/protests_blm_maryland_20200525_20200606_v3.csv\"\n",
    "massachusetts_file = \"protests_project/protests_blm_massachusetts_20200525_20200606_v3.csv\"\n",
    "michigan_file = \"protests_project/protests_blm_michigan_20200525_20200606_v3.csv\"\n",
    "minnesota_file = \"protests_project/protests_blm_minnesota_20200525_20200606_v3.csv\"\n",
    "mississippi_file = \"protests_project/protests_blm_mississippi_20200525_20200606_v3.csv\"\n",
    "missouri_file = \"protests_project/protests_blm_missouri_20200525_20200606_v3.csv\"\n",
    "montana_file = \"protests_project/protests_blm_montana_20200525_20200606_v3.csv\"\n",
    "nebraska_file = \"protests_project/protests_blm_nebraska_20200525_20200606_v3.csv\"\n",
    "nevada_file = \"protests_project/protests_blm_nevada_20200525_20200606_v3.csv\"\n",
    "new_hampshire_file = \"protests_project/protests_blm_new_hampshire_20200525_20200606_v3.csv\"\n",
    "new_jersey_file = \"protests_project/protests_blm_new_jersey_20200525_20200606_v3.csv\"\n",
    "new_mexico_file = \"protests_project/protests_blm_new_mexico_20200525_20200606_v3.csv\"\n",
    "new_york_file = \"protests_project/protests_blm_new_york_20200525_20200606_v3.csv\"\n",
    "north_carolina_file = \"protests_project/protests_blm_north_carolina_20200525_20200606_v3.csv\"\n",
    "north_dakota_file = \"protests_project/protests_blm_north_dakota_20200525_20200606_v3.csv\"\n",
    "ohio_file = \"protests_project/protests_blm_ohio_20200525_20200606_v3.csv\"\n",
    "oklahoma_file = \"protests_project/protests_blm_oklahoma_20200525_20200606_v3.csv\"\n",
    "oregon_file = \"protests_project/protests_blm_oregon_20200525_20200606_v3.csv\"\n",
    "pennsylvania_file = \"protests_project/protests_blm_pennsylvania_20200525_20200606_v3.csv\"\n",
    "rhode_island_file = \"protests_project/protests_blm_rhode_island_20200525_20200606_v3.csv\"\n",
    "south_carolina_file = \"protests_project/protests_blm_south_carolina_20200525_20200606_v3.csv\"\n",
    "south_dakota_file = \"protests_project/protests_blm_south_dakota_20200525_20200606_v3.csv\"\n",
    "tennessee_file = \"protests_project/protests_blm_tennessee_20200525_20200606_v3.csv\"\n",
    "texas_file = \"protests_project/protests_blm_texas_20200525_20200606_v3.csv\"\n",
    "utah_file = \"protests_project/protests_blm_utah_20200525_20200606_v3.csv\"\n",
    "vermont_file = \"protests_project/protests_blm_vermont_20200525_20200606_v3.csv\"\n",
    "virginia_file = \"protests_project/protests_blm_virginia_20200525_20200606_v3.csv\"\n",
    "washington_file = \"protests_project/protests_blm_washington_20200525_20200606_v3.csv\"\n",
    "west_virginia_file = \"protests_project/protests_blm_west_virginia_20200525_20200606_v3.csv\"\n",
    "wisconsin_file = \"protests_project/protests_blm_wisconsin_20200525_20200606_v3.csv\"\n",
    "wyoming_file = \"protests_project/protests_blm_wyoming_20200525_20200606_v3.csv\"\n",
    "district_columbia_file = \"protests_project/protests_blm_district_columbia_20200525_20200606_v3.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding dataframes\n",
    "alabama_news_df = pd.read_csv(alabama_file)\n",
    "alaska_news_df = pd.read_csv(alaska_file)\n",
    "arizona_news_df = pd.read_csv(arizona_file)\n",
    "arkansas_news_df = pd.read_csv(arkansas_file)\n",
    "california_news_df = pd.read_csv(california_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorado_news_df = pd.read_csv(colorado_file)\n",
    "connecticut_news_df = pd.read_csv(connecticut_file)\n",
    "delaware_news_df = pd.read_csv(delaware_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "georgia_news_df = pd.read_csv(georgia_file) \n",
    "hawaii_news_df = pd.read_csv(hawaii_file) \n",
    "idaho_news_df = pd.read_csv(idaho_file)\n",
    "illinois_news_df = pd.read_csv(illinois_file)\n",
    "indiana_news_df = pd.read_csv(indiana_file) \n",
    "iowa_news_df = pd.read_csv(iowa_file)\n",
    "kansas_news_df = pd.read_csv(kansas_file)\n",
    "kentucky_news_df = pd.read_csv(kentucky_file)\n",
    "louisiana_news_df = pd.read_csv(louisiana_file) \n",
    "maine_news_df = pd.read_csv(maine_file) \n",
    "maryland_news_df = pd.read_csv(maryland_file) \n",
    "massachusetts_news_df = pd.read_csv(massachusetts_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "michigan_news_df = pd.read_csv(michigan_file)\n",
    "minnesota_news_df = pd.read_csv(minnesota_file)\n",
    "mississippi_news_df = pd.read_csv(mississippi_file)\n",
    "missouri_news_df = pd.read_csv(missouri_file)\n",
    "montana_news_df = pd.read_csv(montana_file)\n",
    "nebraska_news_df = pd.read_csv(nebraska_file) \n",
    "nevada_news_df = pd.read_csv(nevada_file) \n",
    "new_hampshire_news_df = pd.read_csv(new_hampshire_file)\n",
    "new_jersey_news_df = pd.read_csv(new_jersey_file) \n",
    "new_mexico_news_df = pd.read_csv(new_mexico_file) \n",
    "new_york_news_df = pd.read_csv(new_york_file) \n",
    "north_carolina_news_df = pd.read_csv(north_carolina_file) \n",
    "north_dakota_news_df = pd.read_csv(north_dakota_file)\n",
    "ohio_news_df = pd.read_csv(ohio_file)\n",
    "oklahoma_news_df = pd.read_csv(oklahoma_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "oregon_news_df = pd.read_csv(oregon_file)\n",
    "pennsylvania_news_df = pd.read_csv(pennsylvania_file) \n",
    "rhode_island_news_df = pd.read_csv(rhode_island_file) \n",
    "south_carolina_news_df = pd.read_csv(south_carolina_file)\n",
    "south_dakota_news_df = pd.read_csv(south_dakota_file) \n",
    "tennessee_news_df = pd.read_csv(tennessee_file)\n",
    "texas_news_df = pd.read_csv(texas_file)\n",
    "utah_news_df = pd.read_csv(utah_file)\n",
    "vermont_news_df = pd.read_csv(vermont_file) \n",
    "virginia_news_df = pd.read_csv(virginia_file) \n",
    "washington_news_df = pd.read_csv(washington_file)\n",
    "west_virginia_news_df = pd.read_csv(west_virginia_file) \n",
    "wisconsin_news_df = pd.read_csv(wisconsin_file) \n",
    "wyoming_news_df = pd.read_csv(wyoming_file) \n",
    "district_columbia_news_df = pd.read_csv(district_columbia_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of articles for each news media\n",
    "alabama_news_size = alabama_news_df.shape[0]\n",
    "alaska_news_size = alaska_news_df.shape[0]\n",
    "arizona_news_size = arizona_news_df.shape[0]\n",
    "arkansas_news_size = arkansas_news_df.shape[0]\n",
    "california_news_size = california_news_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorado_news_size = colorado_news_df.shape[0]\n",
    "connecticut_news_size = connecticut_news_df.shape[0]\n",
    "delaware_news_size = delaware_news_df.shape[0]\n",
    "georgia_news_size = georgia_news_df.shape[0]\n",
    "hawaii_news_size = hawaii_news_df.shape[0]\n",
    "idaho_news_size = idaho_news_df.shape[0]\n",
    "illinois_news_size = illinois_news_df.shape[0]\n",
    "indiana_news_size = indiana_news_df.shape[0] \n",
    "iowa_news_size = iowa_news_df.shape[0]\n",
    "kansas_news_size = kansas_news_df.shape[0]\n",
    "kentucky_news_size = kentucky_news_df.shape[0]\n",
    "louisiana_news_size = louisiana_news_df.shape[0]\n",
    "maine_news_size = maine_news_df.shape[0]\n",
    "maryland_news_size = maryland_news_df.shape[0]\n",
    "massachusetts_news_size = massachusetts_news_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "michigan_news_size = michigan_news_df.shape[0]\n",
    "minnesota_news_size = minnesota_news_df.shape[0]\n",
    "mississippi_news_size = mississippi_news_df.shape[0]\n",
    "missouri_news_size = missouri_news_df.shape[0]\n",
    "montana_news_size = montana_news_df.shape[0]\n",
    "nebraska_news_size = nebraska_news_df.shape[0] \n",
    "nevada_news_size = nevada_news_df.shape[0] \n",
    "new_hampshire_news_size = new_hampshire_news_df.shape[0]\n",
    "new_jersey_news_size = new_jersey_news_df.shape[0]\n",
    "new_mexico_news_size = new_mexico_news_df.shape[0]\n",
    "new_york_news_size = new_york_news_df.shape[0]\n",
    "north_carolina_news_size = north_carolina_news_df.shape[0]\n",
    "north_dakota_news_size = north_dakota_news_df.shape[0]\n",
    "ohio_news_size = ohio_news_df.shape[0]\n",
    "oklahoma_news_size = oklahoma_news_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "oregon_news_size = oregon_news_df.shape[0]\n",
    "pennsylvania_news_size = pennsylvania_news_df.shape[0]\n",
    "rhode_island_news_size = rhode_island_news_df.shape[0]\n",
    "south_carolina_news_size = south_carolina_news_df.shape[0]\n",
    "south_dakota_news_size = south_dakota_news_df.shape[0]\n",
    "tennessee_news_size = tennessee_news_df.shape[0]\n",
    "texas_news_size = texas_news_df.shape[0]\n",
    "utah_news_size = utah_news_df.shape[0]\n",
    "vermont_news_size = vermont_news_df.shape[0]\n",
    "virginia_news_size = virginia_news_df.shape[0]\n",
    "washington_news_size = washington_news_df.shape[0]\n",
    "west_virginia_news_size = west_virginia_news_df.shape[0]\n",
    "wisconsin_news_size = wisconsin_news_df.shape[0]\n",
    "wyoming_news_size = wyoming_news_df.shape[0]\n",
    "district_columbia_news_size = district_columbia_news_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama:  555\n",
      "Alaska:  211\n",
      "Arizona:  3784\n",
      "Arkansas:  1170\n",
      "California:  17146\n"
     ]
    }
   ],
   "source": [
    "# Number of articles per state - 05/25/2020 to 06/06/2020\n",
    "print('Alabama: ', alabama_news_size)\n",
    "print('Alaska: ', alaska_news_size)\n",
    "print('Arizona: ', arizona_news_size)\n",
    "print('Arkansas: ', arkansas_news_size)\n",
    "print('California: ', california_news_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colorado :  1525\n",
      "Connecticut :  771\n",
      "Delaware :  222\n",
      "Georgia :  1819\n",
      "Hawaii :  182\n",
      "Idaho :  4380\n",
      "Illinois :  254\n",
      "Indiana :  1589\n",
      "Iowa :  1047\n",
      "Kansas :  1598\n",
      "Kentucky :  490\n",
      "Louisiana :  753\n",
      "Maine :  442\n",
      "Maryland :  775\n",
      "Massachusetts :  3801\n"
     ]
    }
   ],
   "source": [
    "print('Colorado : ', colorado_news_size)\n",
    "print('Connecticut : ', connecticut_news_size)\n",
    "print('Delaware : ', delaware_news_size)\n",
    "print('Georgia : ', georgia_news_size)\n",
    "print('Hawaii : ', hawaii_news_size)\n",
    "print('Idaho : ', idaho_news_size)\n",
    "print('Illinois : ', illinois_news_size)\n",
    "print('Indiana : ', indiana_news_size)\n",
    "print('Iowa : ', iowa_news_size)\n",
    "print('Kansas : ', kansas_news_size)\n",
    "print('Kentucky : ', kentucky_news_size)\n",
    "print('Louisiana : ', louisiana_news_size)\n",
    "print('Maine : ', maine_news_size)\n",
    "print('Maryland : ', maryland_news_size)\n",
    "print('Massachusetts : ', massachusetts_news_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michigan:  1339\n",
      "Minnesota:  1971\n",
      "Mississipi:  224\n",
      "Missouri:  1100\n",
      "Montana:  153\n",
      "Nebraska:  307\n",
      "Nevada:  1075\n",
      "New Hampshire:  445\n",
      "New Jersey:  457\n",
      "New Mexico:  608\n",
      "New York:  3732\n",
      "North Carolina:  1195\n",
      "North Dakota:  384\n",
      "Ohio:  3790\n",
      "Oklahoma:  677\n"
     ]
    }
   ],
   "source": [
    "print('Michigan: ', michigan_news_size)\n",
    "print('Minnesota: ', minnesota_news_size)\n",
    "print('Mississipi: ', mississippi_news_size)\n",
    "print('Missouri: ', missouri_news_size) \n",
    "print('Montana: ', montana_news_size)\n",
    "print('Nebraska: ', nebraska_news_size)\n",
    "print('Nevada: ', nevada_news_size)\n",
    "print('New Hampshire: ', new_hampshire_news_size)\n",
    "print('New Jersey: ', new_jersey_news_size)\n",
    "print('New Mexico: ', new_mexico_news_size)\n",
    "print('New York: ', new_york_news_size)\n",
    "print('North Carolina: ', north_carolina_news_size)\n",
    "print('North Dakota: ', north_dakota_news_size)\n",
    "print('Ohio: ', ohio_news_size)\n",
    "print('Oklahoma: ', oklahoma_news_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oregon:  416\n",
      "Pennsylvania:  1238\n",
      "Rhode Island:  540\n",
      "South Carolina:  1102\n",
      "South Dakota:  346\n",
      "Tennessee:  709\n",
      "Texas:  4184\n",
      "Utah:  442\n",
      "Vermont:  81\n",
      "Virginia:  700\n",
      "Washington:  1251\n",
      "West Virginia:  337\n",
      "Wisconsin:  2111\n",
      "Wyoming:  139\n",
      "District of Columbia:  862\n"
     ]
    }
   ],
   "source": [
    "print('Oregon: ', oregon_news_size)\n",
    "print('Pennsylvania: ', pennsylvania_news_size)\n",
    "print('Rhode Island: ', rhode_island_news_size)\n",
    "print('South Carolina: ', south_carolina_news_size)\n",
    "print('South Dakota: ', south_dakota_news_size)\n",
    "print('Tennessee: ', tennessee_news_size)\n",
    "print('Texas: ', texas_news_size)\n",
    "print('Utah: ', utah_news_size)\n",
    "print('Vermont: ', vermont_news_size)\n",
    "print('Virginia: ', virginia_news_size)\n",
    "print('Washington: ', washington_news_size)\n",
    "print('West Virginia: ', west_virginia_news_size)\n",
    "print('Wisconsin: ', wisconsin_news_size)\n",
    "print('Wyoming: ', wyoming_news_size)\n",
    "print('District of Columbia: ', district_columbia_news_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alabama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles to be processed:  555\n",
      "Currently processing article number:  0\n",
      "Currently processing article number:  100\n",
      "Currently processing article number:  200\n",
      "Currently processing article number:  300\n",
      "Currently processing article number:  400\n",
      "Currently processing article number:  500\n"
     ]
    }
   ],
   "source": [
    "print('Number of articles to be processed: ', alabama_news_size)\n",
    "\n",
    "for i in range(alabama_news_size):\n",
    "    # Where are we?\n",
    "    if i%100 == 0:\n",
    "        print('Currently processing article number: ', i)\n",
    "    # Load article    \n",
    "    url = alabama_news_df.loc[i,\"url\"] \n",
    "    article = Article(url.strip())\n",
    "    \n",
    "    # Extract the text\n",
    "    try:\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        text = article.text\n",
    "        \n",
    "        alabama_news_df.loc[i,\"text\"] = text.replace('\\n\\n', ' ')  \n",
    "        alabama_news_df.loc[i,\"not_available\"] = 0\n",
    "    \n",
    "    # Otherwise, indicate as not available\n",
    "    except:\n",
    "        alabama_news_df.loc[i,\"text\"] = \"NA\"\n",
    "        alabama_news_df.loc[i,\"not_available\"] = 1\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "alabama_news_result_file = \"protests_project/alabama_news_results.csv\"\n",
    "alabama_news_df.to_csv(alabama_news_result_file, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    490\n",
       "1.0     65\n",
       "Name: not_available, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alabama_news_df['not_available'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.882883\n",
       "1.0    0.117117\n",
       "Name: not_available, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alabama_news_df['not_available'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alaska"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles to be processed:  211\n",
      "Currently processing article number:  0\n",
      "Currently processing article number:  100\n",
      "Currently processing article number:  200\n"
     ]
    }
   ],
   "source": [
    "print('Number of articles to be processed: ', alaska_news_size)\n",
    "\n",
    "for i in range(alaska_news_size):\n",
    "    # Where are we?\n",
    "    if i%100 == 0:\n",
    "        print('Currently processing article number: ', i)\n",
    "    # Load article    \n",
    "    url = alaska_news_df.loc[i,\"url\"] \n",
    "    article = Article(url.strip())\n",
    "    \n",
    "    # Extract the text\n",
    "    try:\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        text = article.text\n",
    "        \n",
    "        alaska_news_df.loc[i,\"text\"] = text.replace('\\n\\n', ' ')  \n",
    "        alaska_news_df.loc[i,\"not_available\"] = 0\n",
    "    \n",
    "    # Otherwise, indicate as not available\n",
    "    except:\n",
    "        alaska_news_df.loc[i,\"text\"] = \"NA\"\n",
    "        alaska_news_df.loc[i,\"not_available\"] = 1\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alaska_news_result_file = \"protests_project/alaska_news_results.csv\"\n",
    "alaska_news_df.to_csv(alaska_news_result_file, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    147\n",
       "1.0     64\n",
       "Name: not_available, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alaska_news_df['not_available'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.696682\n",
       "1.0    0.303318\n",
       "Name: not_available, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alaska_news_df['not_available'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arizona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles to be processed:  3784\n",
      "Currently processing article number:  0\n",
      "Currently processing article number:  100\n",
      "Currently processing article number:  200\n",
      "Currently processing article number:  300\n",
      "Currently processing article number:  400\n",
      "Currently processing article number:  500\n",
      "Currently processing article number:  600\n",
      "Currently processing article number:  700\n",
      "Currently processing article number:  800\n",
      "Currently processing article number:  900\n",
      "Currently processing article number:  1000\n",
      "Currently processing article number:  1100\n",
      "Currently processing article number:  1200\n",
      "Currently processing article number:  1300\n",
      "Currently processing article number:  1400\n",
      "Currently processing article number:  1500\n",
      "Currently processing article number:  1600\n",
      "Currently processing article number:  1700\n",
      "Currently processing article number:  1800\n",
      "Currently processing article number:  1900\n",
      "Currently processing article number:  2000\n",
      "Currently processing article number:  2100\n",
      "Currently processing article number:  2200\n",
      "Currently processing article number:  2300\n",
      "Currently processing article number:  2400\n",
      "Currently processing article number:  2500\n",
      "Currently processing article number:  2600\n",
      "Currently processing article number:  2700\n",
      "Currently processing article number:  2800\n",
      "Currently processing article number:  2900\n",
      "Currently processing article number:  3000\n",
      "Currently processing article number:  3100\n",
      "Currently processing article number:  3200\n",
      "Currently processing article number:  3300\n",
      "Currently processing article number:  3400\n",
      "Currently processing article number:  3500\n",
      "Currently processing article number:  3600\n",
      "Currently processing article number:  3700\n"
     ]
    }
   ],
   "source": [
    "print('Number of articles to be processed: ',arizona_news_size)\n",
    "\n",
    "for i in range(arizona_news_size):\n",
    "    # Where are we?\n",
    "    if i%100 == 0:\n",
    "        print('Currently processing article number: ', i)\n",
    "    # Load article    \n",
    "    url = arizona_news_df.loc[i,\"url\"] \n",
    "    article = Article(url.strip())\n",
    "    \n",
    "    # Extract the text\n",
    "    try:\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        text = article.text\n",
    "        \n",
    "        arizona_news_df.loc[i,\"text\"] = text.replace('\\n\\n', ' ')  \n",
    "        arizona_news_df.loc[i,\"not_available\"] = 0\n",
    "    \n",
    "    # Otherwise, indicate as not available\n",
    "    except:\n",
    "        arizona_news_df.loc[i,\"text\"] = \"NA\"\n",
    "        arizona_news_df.loc[i,\"not_available\"] = 1\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arizona_news_result_file = \"protests_project/arizona_news_results.csv\"\n",
    "arizona_news_df.to_csv(arizona_news_result_file, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    3725\n",
       "1.0      59\n",
       "Name: not_available, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arizona_news_df['not_available'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.984408\n",
       "1.0    0.015592\n",
       "Name: not_available, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arizona_news_df['not_available'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arkansas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles to be processed:  1170\n",
      "Currently processing article number:  0\n",
      "Currently processing article number:  100\n",
      "Currently processing article number:  200\n",
      "Currently processing article number:  300\n",
      "Currently processing article number:  400\n",
      "Currently processing article number:  500\n",
      "Currently processing article number:  600\n",
      "Currently processing article number:  700\n",
      "Currently processing article number:  800\n",
      "Currently processing article number:  900\n",
      "Currently processing article number:  1000\n",
      "Currently processing article number:  1100\n"
     ]
    }
   ],
   "source": [
    "print('Number of articles to be processed: ',arkansas_news_size)\n",
    "\n",
    "for i in range(arkansas_news_size):\n",
    "    # Where are we?\n",
    "    if i%100 == 0:\n",
    "        print('Currently processing article number: ', i)\n",
    "    # Load article    \n",
    "    url = arkansas_news_df.loc[i,\"url\"] \n",
    "    article = Article(url.strip())\n",
    "    \n",
    "    # Extract the text\n",
    "    try:\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        text = article.text\n",
    "        \n",
    "        arkansas_news_df.loc[i,\"text\"] = text.replace('\\n\\n', ' ')  \n",
    "        arkansas_news_df.loc[i,\"not_available\"] = 0\n",
    "    \n",
    "    # Otherwise, indicate as not available\n",
    "    except:\n",
    "        arkansas_news_df.loc[i,\"text\"] = \"NA\"\n",
    "        arkansas_news_df.loc[i,\"not_available\"] = 1\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arkansas_news_result_file = \"protests_project/arkansas_news_results.csv\"\n",
    "arkansas_news_df.to_csv(arkansas_news_result_file, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1160\n",
       "1.0      10\n",
       "Name: not_available, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arkansas_news_df['not_available'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.991453\n",
       "1.0    0.008547\n",
       "Name: not_available, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arkansas_news_df['not_available'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles to be processed:  17146\n",
      "Currently processing article number:  0\n",
      "Currently processing article number:  100\n",
      "Currently processing article number:  200\n",
      "Currently processing article number:  300\n",
      "Currently processing article number:  400\n",
      "Currently processing article number:  500\n",
      "Currently processing article number:  600\n",
      "Currently processing article number:  700\n",
      "Currently processing article number:  800\n",
      "Currently processing article number:  900\n",
      "Currently processing article number:  1000\n",
      "Currently processing article number:  1100\n",
      "Currently processing article number:  1200\n",
      "Currently processing article number:  1300\n",
      "Currently processing article number:  1400\n",
      "Currently processing article number:  1500\n",
      "Currently processing article number:  1600\n",
      "Currently processing article number:  1700\n",
      "Currently processing article number:  1800\n",
      "Currently processing article number:  1900\n",
      "Currently processing article number:  2000\n",
      "Currently processing article number:  2100\n",
      "Currently processing article number:  2200\n",
      "Currently processing article number:  2300\n",
      "Currently processing article number:  2400\n",
      "Currently processing article number:  2500\n",
      "Currently processing article number:  2600\n",
      "Currently processing article number:  2700\n",
      "Currently processing article number:  2800\n",
      "Currently processing article number:  2900\n",
      "Currently processing article number:  3000\n",
      "Currently processing article number:  3100\n",
      "Currently processing article number:  3200\n",
      "Currently processing article number:  3300\n",
      "Currently processing article number:  3400\n",
      "Currently processing article number:  3500\n",
      "Currently processing article number:  3600\n",
      "Currently processing article number:  3700\n",
      "Currently processing article number:  3800\n",
      "Currently processing article number:  3900\n",
      "Currently processing article number:  4000\n",
      "Currently processing article number:  4100\n",
      "Currently processing article number:  4200\n",
      "Currently processing article number:  4300\n",
      "Currently processing article number:  4400\n",
      "Currently processing article number:  4500\n",
      "Currently processing article number:  4600\n",
      "Currently processing article number:  4700\n",
      "Currently processing article number:  4800\n",
      "Currently processing article number:  4900\n",
      "Currently processing article number:  5000\n",
      "Currently processing article number:  5100\n",
      "Currently processing article number:  5200\n",
      "Currently processing article number:  5300\n",
      "Currently processing article number:  5400\n",
      "Currently processing article number:  5500\n",
      "Currently processing article number:  5600\n",
      "Currently processing article number:  5700\n",
      "Currently processing article number:  5800\n",
      "Currently processing article number:  5900\n",
      "Currently processing article number:  6000\n",
      "Currently processing article number:  6100\n",
      "Currently processing article number:  6200\n",
      "Currently processing article number:  6300\n",
      "Currently processing article number:  6400\n",
      "Currently processing article number:  6500\n",
      "Currently processing article number:  6600\n",
      "Currently processing article number:  6700\n",
      "Currently processing article number:  6800\n",
      "Currently processing article number:  6900\n",
      "Currently processing article number:  7000\n",
      "Currently processing article number:  7100\n",
      "Currently processing article number:  7200\n",
      "Currently processing article number:  7300\n",
      "Currently processing article number:  7400\n",
      "Currently processing article number:  7500\n",
      "Currently processing article number:  7600\n",
      "Currently processing article number:  7700\n",
      "Currently processing article number:  7800\n",
      "Currently processing article number:  7900\n",
      "Currently processing article number:  8000\n",
      "Currently processing article number:  8100\n",
      "Currently processing article number:  8200\n",
      "Currently processing article number:  8300\n",
      "Currently processing article number:  8400\n",
      "Currently processing article number:  8500\n",
      "Currently processing article number:  8600\n",
      "Currently processing article number:  8700\n",
      "Currently processing article number:  8800\n",
      "Currently processing article number:  8900\n",
      "Currently processing article number:  9000\n",
      "Currently processing article number:  9100\n",
      "Currently processing article number:  9200\n",
      "Currently processing article number:  9300\n",
      "Currently processing article number:  9400\n",
      "Currently processing article number:  9500\n",
      "Currently processing article number:  9600\n",
      "Currently processing article number:  9700\n",
      "Currently processing article number:  9800\n",
      "Currently processing article number:  9900\n",
      "Currently processing article number:  10000\n",
      "Currently processing article number:  10100\n",
      "Currently processing article number:  10200\n",
      "Currently processing article number:  10300\n",
      "Currently processing article number:  10400\n",
      "Currently processing article number:  10500\n",
      "Currently processing article number:  10600\n",
      "Currently processing article number:  10700\n",
      "Currently processing article number:  10800\n",
      "Currently processing article number:  10900\n",
      "Currently processing article number:  11000\n",
      "Currently processing article number:  11100\n",
      "Currently processing article number:  11200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marie CHARPIGNON\\Anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py:1206: UnknownTimezoneWarning: tzname PDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  category=UnknownTimezoneWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing article number:  11300\n",
      "Currently processing article number:  11400\n",
      "Currently processing article number:  11500\n",
      "Currently processing article number:  11600\n",
      "Currently processing article number:  11700\n",
      "Currently processing article number:  11800\n",
      "Currently processing article number:  11900\n",
      "Currently processing article number:  12000\n",
      "Currently processing article number:  12100\n",
      "Currently processing article number:  12200\n",
      "Currently processing article number:  12300\n",
      "Currently processing article number:  12400\n",
      "Currently processing article number:  12500\n",
      "Currently processing article number:  12600\n",
      "Currently processing article number:  12700\n",
      "Currently processing article number:  12800\n",
      "Currently processing article number:  12900\n",
      "Currently processing article number:  13000\n",
      "Currently processing article number:  13100\n",
      "Currently processing article number:  13200\n",
      "Currently processing article number:  13300\n",
      "Currently processing article number:  13400\n",
      "Currently processing article number:  13500\n",
      "Currently processing article number:  13600\n",
      "Currently processing article number:  13700\n",
      "Currently processing article number:  13800\n",
      "Currently processing article number:  13900\n",
      "Currently processing article number:  14000\n",
      "Currently processing article number:  14100\n",
      "Currently processing article number:  14200\n",
      "Currently processing article number:  14300\n",
      "Currently processing article number:  14400\n",
      "Currently processing article number:  14500\n",
      "Currently processing article number:  14600\n",
      "Currently processing article number:  14700\n",
      "Currently processing article number:  14800\n",
      "Currently processing article number:  14900\n",
      "Currently processing article number:  15000\n",
      "Currently processing article number:  15100\n",
      "Currently processing article number:  15200\n",
      "Currently processing article number:  15300\n",
      "Currently processing article number:  15400\n",
      "Currently processing article number:  15500\n",
      "Currently processing article number:  15600\n",
      "Currently processing article number:  15700\n",
      "Currently processing article number:  15800\n",
      "Currently processing article number:  15900\n",
      "Currently processing article number:  16000\n",
      "Currently processing article number:  16100\n",
      "Currently processing article number:  16200\n",
      "Currently processing article number:  16300\n",
      "Currently processing article number:  16400\n",
      "Currently processing article number:  16500\n",
      "Currently processing article number:  16600\n",
      "Currently processing article number:  16700\n",
      "Currently processing article number:  16800\n",
      "Currently processing article number:  16900\n",
      "Currently processing article number:  17000\n",
      "Currently processing article number:  17100\n"
     ]
    }
   ],
   "source": [
    "print('Number of articles to be processed: ',california_news_size)\n",
    "\n",
    "for i in range(california_news_size):\n",
    "    # Where are we?\n",
    "    if i%100 == 0:\n",
    "        print('Currently processing article number: ', i)\n",
    "    # Load article    \n",
    "    url = california_news_df.loc[i,\"url\"] \n",
    "    article = Article(url.strip())\n",
    "    \n",
    "    # Extract the text\n",
    "    try:\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        text = article.text\n",
    "        \n",
    "        california_news_df.loc[i,\"text\"] = text.replace('\\n\\n', ' ')  \n",
    "        california_news_df.loc[i,\"not_available\"] = 0\n",
    "    \n",
    "    # Otherwise, indicate as not available\n",
    "    except:\n",
    "        california_news_df.loc[i,\"text\"] = \"NA\"\n",
    "        california_news_df.loc[i,\"not_available\"] = 1\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "california_news_result_file = \"protests_project/california_news_results.csv\"\n",
    "california_news_df.to_csv(california_news_result_file, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.984719\n",
       "1.0    0.015281\n",
       "Name: not_available, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_news_df['not_available'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colorado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles to be processed:  1525\n",
      "Currently processing article number:  0\n",
      "Currently processing article number:  100\n",
      "Currently processing article number:  200\n",
      "Currently processing article number:  300\n",
      "Currently processing article number:  400\n",
      "Currently processing article number:  500\n",
      "Currently processing article number:  600\n",
      "Currently processing article number:  700\n",
      "Currently processing article number:  800\n",
      "Currently processing article number:  900\n",
      "Currently processing article number:  1000\n",
      "Currently processing article number:  1100\n",
      "Currently processing article number:  1200\n",
      "Currently processing article number:  1300\n",
      "Currently processing article number:  1400\n",
      "Currently processing article number:  1500\n"
     ]
    }
   ],
   "source": [
    "print('Number of articles to be processed: ', colorado_news_size)\n",
    "\n",
    "for i in range(colorado_news_size):\n",
    "    # Where are we?\n",
    "    if i%100 == 0:\n",
    "        print('Currently processing article number: ', i)\n",
    "    # Load article    \n",
    "    url = colorado_news_df.loc[i,\"url\"] \n",
    "    article = Article(url.strip())\n",
    "    \n",
    "    # Extract the text\n",
    "    try:\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        text = article.text\n",
    "        \n",
    "        colorado_news_df.loc[i,\"text\"] = text.replace('\\n\\n', ' ')  \n",
    "        colorado_news_df.loc[i,\"not_available\"] = 0\n",
    "    \n",
    "    # Otherwise, indicate as not available\n",
    "    except:\n",
    "        colorado_news_df.loc[i,\"text\"] = \"NA\"\n",
    "        colorado_news_df.loc[i,\"not_available\"] = 1\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorado_news_result_file = \"protests_project/colorado_news_results.csv\"\n",
    "colorado_news_df.to_csv(colorado_news_result_file, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1449\n",
       "1.0      76\n",
       "Name: not_available, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorado_news_df['not_available'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.950164\n",
       "1.0    0.049836\n",
       "Name: not_available, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorado_news_df['not_available'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecticut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles to be processed:  771\n",
      "Currently processing article number:  0\n",
      "Currently processing article number:  100\n",
      "Currently processing article number:  200\n",
      "Currently processing article number:  300\n",
      "Currently processing article number:  400\n",
      "Currently processing article number:  500\n",
      "Currently processing article number:  600\n",
      "Currently processing article number:  700\n"
     ]
    }
   ],
   "source": [
    "print('Number of articles to be processed: ', connecticut_news_size)\n",
    "\n",
    "for i in range(connecticut_news_size):\n",
    "    # Where are we?\n",
    "    if i%100 == 0:\n",
    "        print('Currently processing article number: ', i)\n",
    "    # Load article    \n",
    "    url = connecticut_news_df.loc[i,\"url\"] \n",
    "    article = Article(url.strip())\n",
    "    \n",
    "    # Extract the text\n",
    "    try:\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        text = article.text\n",
    "        \n",
    "        connecticut_news_df.loc[i,\"text\"] = text.replace('\\n\\n', ' ')  \n",
    "        connecticut_news_df.loc[i,\"not_available\"] = 0\n",
    "    \n",
    "    # Otherwise, indicate as not available\n",
    "    except:\n",
    "        connecticut_news_df.loc[i,\"text\"] = \"NA\"\n",
    "        connecticut_news_df.loc[i,\"not_available\"] = 1\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "connecticut_news_result_file = \"protests_project/connecticut_news_results.csv\"\n",
    "connecticut_news_df.to_csv(connecticut_news_result_file, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    719\n",
       "1.0     52\n",
       "Name: not_available, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connecticut_news_df['not_available'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.932555\n",
       "1.0    0.067445\n",
       "Name: not_available, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connecticut_news_df['not_available'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delaware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles to be processed:  222\n",
      "Currently processing article number:  0\n",
      "Currently processing article number:  100\n",
      "Currently processing article number:  200\n"
     ]
    }
   ],
   "source": [
    "print('Number of articles to be processed: ', delaware_news_size)\n",
    "\n",
    "for i in range(delaware_news_size):\n",
    "    # Where are we?\n",
    "    if i%100 == 0:\n",
    "        print('Currently processing article number: ', i)\n",
    "    # Load article    \n",
    "    url = delaware_news_df.loc[i,\"url\"] \n",
    "    article = Article(url.strip())\n",
    "    \n",
    "    # Extract the text\n",
    "    try:\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        text = article.text\n",
    "        \n",
    "        delaware_news_df.loc[i,\"text\"] = text.replace('\\n\\n', ' ')  \n",
    "        delaware_news_df.loc[i,\"not_available\"] = 0\n",
    "    \n",
    "    # Otherwise, indicate as not available\n",
    "    except:\n",
    "        delaware_news_df.loc[i,\"text\"] = \"NA\"\n",
    "        delaware_news_df.loc[i,\"not_available\"] = 1\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "delaware_news_result_file = \"protests_project/delaware_news_results.csv\"\n",
    "delaware_news_df.to_csv(delaware_news_result_file, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    171\n",
       "1.0     51\n",
       "Name: not_available, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delaware_news_df['not_available'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.77027\n",
       "1.0    0.22973\n",
       "Name: not_available, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delaware_news_df['not_available'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Georgia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hawaii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idaho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illinois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kansas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kentucky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Louisiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maryland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Massachusetts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
